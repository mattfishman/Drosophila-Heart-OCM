{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drosophila Heart OCM (FlyNet 2.0+) training code\n",
    "\n",
    "**Author**: Matthew Fishman\n",
    "\n",
    "**Date**: December 1, 2022\n",
    "\n",
    "**Description**: This notebook contains the training code to build FlyNet from scratch using the data that can be found on Figshare. A complete description of the model can be found within the Scientific Data manuscript. Data directory paths need to be updated before running.\n",
    "\n",
    "**Requirements**:\n",
    "- Python 3.9\n",
    "- Libraries: cudatoolkit=11.2 cudnn=8.1.0 tensorflow=2.10 scikit-image opencv-python\n",
    "\n",
    "**License**: MIT License\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Tensorflow and Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import ConvLSTM2D, Conv2DTranspose, TimeDistributed, Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import Input, MaxPooling2D, BatchNormalization, LeakyReLU, Concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import loss_funcs as lf\n",
    "\n",
    "# Import numpy and data management\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from random import shuffle\n",
    "from random import randint\n",
    "from random import sample\n",
    "import skimage.io\n",
    "from skimage import transform\n",
    "import cv2\n",
    "\n",
    "# Optional imports for data visualization (tensorboard)\n",
    "# Import tensorboard\n",
    "# %load_ext tensorboard\n",
    "\n",
    "# Set all constants needed for training the model \n",
    "IMAGE_SIZE = \"full\" # which files to read (full size images are cropped and augmented by default during training)\n",
    "\n",
    "# Directory where the data is stored (change this to your own directory)\n",
    "DATA_DIR = \"C:/Users/username/Downloads/Drosophila_heart_OCM_dataset\"\n",
    "OUTPUT_DIR = \"C:/Users/username/Downloads/Output\"\n",
    "\n",
    "DATA_DIR = \"D:/Drosophila_heart_OCM_dataset\"\n",
    "OUTPUT_DIR = \"D:/FlyNet/Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for reading in and processing the data\n",
    "def generate_pk(path):\n",
    "    \"\"\"\n",
    "    Generate a pickle file containing the paths to the individual samples\n",
    "    \n",
    "    Parameters:\n",
    "    path (str): path to the directory containing the data\n",
    "\n",
    "    Returns:\n",
    "    pickle_path (str): path to the generated pickle file in OUTPUT_DIR\n",
    "    \"\"\"\n",
    "    # Get a list of all the directories in the data directory\n",
    "    dirs = os.listdir(path)\n",
    "    # Initialize a list to store the paths to the individual samples\n",
    "    data = []\n",
    "    # Iterate through each directory\n",
    "    for dir in dirs:\n",
    "        # Get the path to the directory\n",
    "        dir_path = os.path.join(path, dir)\n",
    "        data.append(dir_path)\n",
    "\n",
    "    # Save the data to a pickle file\n",
    "    pickle_path = os.path.join(OUTPUT_DIR, \"data.pkl\").replace(\"\\\\\",\"/\")\n",
    "    with open(pickle_path, mode='wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    return pickle_path\n",
    "\n",
    "def read_pk(path):\n",
    "    \"\"\"\n",
    "    Read in a pickle file and return the data split into training and validation sets\n",
    "\n",
    "    Parameters:\n",
    "    path (str): path to the pickle file\n",
    "\n",
    "    Returns:\n",
    "    data (np.array): array of paths to individual samples\n",
    "    train_ids (np.array): array of training indices\n",
    "    val_ids (np.array): array of validation indices\n",
    "    \"\"\"\n",
    "    with open(path, mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    data=np.array(data)\n",
    "    available_ids = np.array(range(len(data)))\n",
    "    shuffle(available_ids)\n",
    "\n",
    "    # ADJUST TRAINING PERCENTAGE HERE\n",
    "    training_percent = 0.95\n",
    "    final_train_id = int(len(available_ids)*training_percent)\n",
    "    train_ids = available_ids[:final_train_id]\n",
    "    val_ids = available_ids[final_train_id:]\n",
    "\n",
    "    return data, train_ids, val_ids\n",
    "\n",
    "def getImg(path):\n",
    "    \"\"\"\n",
    "    Get the path to the image file in the directory\n",
    "\n",
    "    Parameters:\n",
    "    path (str): path to the directory\n",
    "\n",
    "    Returns:\n",
    "    file_path (str): path to the image file\n",
    "    \"\"\"\n",
    "    global IMAGE_SIZE\n",
    "    # Get a list of files in the directory\n",
    "    files = os.listdir(path)\n",
    "    # Get the file with \"resize\" in the name\n",
    "    search_string = IMAGE_SIZE + \"_img.tiff\"\n",
    "\n",
    "    for file in files:\n",
    "        if search_string in file:\n",
    "            file_path = os.path.join(path, file).replace(\"\\\\\",\"/\")\n",
    "            return file_path\n",
    "    print(\"No resize file found\")\n",
    "\n",
    "def getMask(path):\n",
    "    \"\"\"\n",
    "    Get the path to the mask file in the directory\n",
    "\n",
    "    Parameters:\n",
    "    path (str): path to the directory\n",
    "\n",
    "    Returns:\n",
    "    file_path (str): path to the mask file\n",
    "    \"\"\"\n",
    "    global IMAGE_SIZE\n",
    "    # Get a list of files in the directory\n",
    "    files = os.listdir(path)\n",
    "    # Get the file with \"mask\" in the name\n",
    "    search_string = IMAGE_SIZE + \"_mask.tiff\"\n",
    "    for file in files:\n",
    "        if search_string in file:\n",
    "            file_path = os.path.join(path, file).replace(\"\\\\\",\"/\")\n",
    "            return file_path\n",
    "    print(\"No mask file found\")\n",
    "\n",
    "def getResizeImg(path):\n",
    "    \"\"\"\n",
    "    Get the path to the resized image file in the directory\n",
    "\n",
    "    Parameters:\n",
    "    path (str): path to the directory\n",
    "\n",
    "    Returns:\n",
    "    file_path (str): path to the resized image file\n",
    "    \"\"\"\n",
    "    # Get a list of files in the directory\n",
    "    files = os.listdir(path)\n",
    "    # Get the file with \"resize\" in the name\n",
    "    search_string = \"resize_img.tiff\"\n",
    "\n",
    "    for file in files:\n",
    "        if search_string in file:\n",
    "            file_path = os.path.join(path, file).replace(\"\\\\\",\"/\")\n",
    "            return file_path\n",
    "    print(\"No resize file found\")\n",
    "\n",
    "def getResizeMask(path):\n",
    "    \"\"\"\n",
    "    Get the path to the resized mask file in the directory\n",
    "\n",
    "    Parameters:\n",
    "    path (str): path to the directory\n",
    "\n",
    "    Returns:\n",
    "    file_path (str): path to the resized mask file\n",
    "    \"\"\"\n",
    "    # Get a list of files in the directory\n",
    "    files = os.listdir(path)\n",
    "    # Get the file with \"mask\" in the name\n",
    "    search_string = \"resize_mask.tiff\"\n",
    "    for file in files:\n",
    "        if search_string in file:\n",
    "            file_path = os.path.join(path, file).replace(\"\\\\\",\"/\")\n",
    "            return file_path\n",
    "    print(\"No mask file found\")\n",
    "\n",
    "def centerVideo(video):\n",
    "    \"\"\"\n",
    "    Center the video by subtracting the mean of all the frames and dividing by the standard deviation\n",
    "\n",
    "    Parameters:\n",
    "    video (np.array): array of video frames\n",
    "\n",
    "    Returns:\n",
    "    centered_video (np.array): array of centered video frames\n",
    "    \"\"\"\n",
    "    mean = np.mean(video)\n",
    "    std = np.std(video)\n",
    "    centered_video = (video - mean) / std\n",
    "    return centered_video\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(data, available_ids, batch_size):\n",
    "    \"\"\"\n",
    "    Generate training data for the model\n",
    "\n",
    "    Parameters:\n",
    "    data (np.array): array of paths to individual samples\n",
    "    available_ids (np.array): array of available indices\n",
    "    batch_size (int): number of samples to generate\n",
    "\n",
    "    Yield:\n",
    "    outputX (np.array): array of training samples\n",
    "    outputY (np.array): array of training labels\n",
    "    \"\"\"\n",
    "    #generate train data\n",
    "    augment = True\n",
    "    while True:\n",
    "        # Choose two random IDs from the available IDs\n",
    "        # INCREASE NUMBER OF SAMPLES HERE IF GPU MEMORY ALLOWS\n",
    "        s = sample(list(available_ids), 2)\n",
    "        outputX = []\n",
    "        outputY = []\n",
    "        for i in s:\n",
    "            # Read the image at that ID and convert it to a numpy array\n",
    "            dir_path = data[i]\n",
    "            mask_path = getMask(dir_path)\n",
    "            resize_path = getImg(dir_path)\n",
    "            img = skimage.io.imread(resize_path)\n",
    "            img = np.array(img)\n",
    "            img = np.squeeze(img)\n",
    "           \n",
    "            # Read the mask file and convert it to a numpy array\n",
    "            img_mask=skimage.io.imread(mask_path)\n",
    "            img_mask=np.array(img_mask)\n",
    "            if(len(img_mask.shape) > 3):\n",
    "                img_mask = (img_mask[:,:,:,0]>0.5)*1.0\n",
    "            else:\n",
    "                img_mask = (img_mask>0.5)*1.0\n",
    "            \n",
    "            # Add a singleton dimension so that all images have a color channel\n",
    "            train = np.array(img)\n",
    "            train=train[...,np.newaxis]\n",
    "            y=np.array(img_mask)\n",
    "            y=y[...,np.newaxis]\n",
    "            \n",
    "            # For training samples shorten to 128 frames per step\n",
    "            last_start = train.shape[0] - batch_size\n",
    "            start_loc = randint(0, last_start)\n",
    "            end_loc = start_loc + batch_size\n",
    "            train = train[start_loc:end_loc]\n",
    "            y = y[start_loc:end_loc]\n",
    "\n",
    "            # The shape of y is [frame, height, width, 1]\n",
    "            # y is a mask with value 0 or 1, find the max and min x and y coordinates of the mask\n",
    "            max_x = np.max(np.where(y == 1)[2])\n",
    "            min_x = np.min(np.where(y == 1)[2])\n",
    "            max_y = np.max(np.where(y == 1)[1])\n",
    "            min_y = np.min(np.where(y == 1)[1])\n",
    "\n",
    "            min_x = 3 if min_x <= 15 else min_x - 12\n",
    "            min_y = 3 if min_y <= 15 else min_y - 12\n",
    "            max_x = 124 if max_x >= 112 else max_x + 12\n",
    "            max_y = 596 if max_y >= 584 else max_y + 12\n",
    "\n",
    "            low = min_y - 30 if min_y - 30 > 1 else 1\n",
    "            high = max_y + 30 if max_y + 30 < y.shape[1] - 1 else y.shape[1] - 1\n",
    "\n",
    "            # Now select the boundaries for the crop\n",
    "            # Make sure the whole mask is in the frame\n",
    "            crop_x_min = randint(2, min_x)\n",
    "            crop_x_max = randint(max_x, 125)\n",
    "            crop_y_min = randint(low, min_y)\n",
    "            crop_y_max = randint(max_y, high)\n",
    "\n",
    "            # Crop the image and mask\n",
    "            train_roi = train[:, crop_y_min:crop_y_max, crop_x_min:crop_x_max]\n",
    "            y_roi = y[:, crop_y_min:crop_y_max, crop_x_min:crop_x_max]\n",
    "\n",
    "            # Now interpolate the image and mask to the original size\n",
    "            train_list = []\n",
    "            y_list = []\n",
    "            for i in range(len(train_roi)):\n",
    "                train_i = cv2.resize(train_roi[i], (128, 128),interpolation=cv2.INTER_CUBIC)\n",
    "                train_list.append(train_i)\n",
    "                y_i = cv2.resize(y_roi[i], (128, 128),interpolation=cv2.INTER_CUBIC)\n",
    "                y_list.append(y_i)\n",
    "\n",
    "            train = np.array(train_list)\n",
    "            y = np.array(y_list)\n",
    "            \n",
    "            if augment:\n",
    "                # Apply random rotation/flip augmentation\n",
    "                aug = randint(0, 2) # Equal chance for each\n",
    "                if aug==0:\n",
    "                    aug_x = train\n",
    "                    aug_y = y\n",
    "                elif aug==1:\n",
    "                    aug_x = np.flip(train, 1)\n",
    "                    aug_y = np.flip(y, 1)\n",
    "                elif aug==2:\n",
    "                    aug_x = np.flip(train, 2)\n",
    "                    aug_y = np.flip(y, 2)\n",
    "                elif aug==3:\n",
    "                    aug_x = np.flip(train, 0)\n",
    "                    aug_y = np.flip(y, 0)\n",
    "                    \n",
    "\n",
    "                # Cast to uint8 before yield\n",
    "                train = aug_x.astype('float32')\n",
    "                y = aug_y.astype('float32')\n",
    "\n",
    "                # Normalize the image\n",
    "                train = centerVideo(train)\n",
    "\n",
    "            else:\n",
    "                train = train.astype('float32')\n",
    "                y = y.astype('float32')\n",
    "\n",
    "                # Normalize the image\n",
    "                train = centerVideo(train)\n",
    "\n",
    "            outputX.append(train)\n",
    "            outputY.append(y)\n",
    "\n",
    "        outputX = np.array(outputX)\n",
    "        outputY = np.array(outputY)\n",
    "\n",
    "        yield (outputX, outputY)\n",
    "\n",
    "\n",
    "def read_validation_files(data, ids):\n",
    "    \"\"\"\n",
    "    Read in the validation files preprocess them the same way and return the validation set\n",
    "\n",
    "    Parameters:\n",
    "    data (np.array): array of paths to individual samples\n",
    "    ids (np.array): array of available indices\n",
    "\n",
    "    Returns:\n",
    "    image (np.array): array of validation samples\n",
    "    y (np.array): array of validation labels\n",
    "    \"\"\"\n",
    "    # make an empty array to hold \n",
    "    image_list = []\n",
    "    mask_list = []\n",
    "    for i in ids:\n",
    "        dir_path = data[i]\n",
    "        mask_path = getResizeMask(dir_path)\n",
    "        resize_path = getResizeImg(dir_path)\n",
    "        img = skimage.io.imread(resize_path)\n",
    "        img = np.array(img)\n",
    "        img = np.squeeze(img)\n",
    "        \n",
    "        # Read the mask file and convert it to a numpy array\n",
    "        # mask_file=input_dir+'/'+input_name+'_mask.tiff'\n",
    "        img_mask=skimage.io.imread(mask_path)\n",
    "        img_mask=np.array(img_mask)\n",
    "        if(len(img_mask.shape) > 3):\n",
    "                img_mask = (img_mask[:,:,:,0]>0.5)*1.0\n",
    "        else:\n",
    "            img_mask = (img_mask>0.5)*1.0\n",
    "        \n",
    "        # Add a singleton dimension so that all images have a color channel\n",
    "        image = np.array(img)\n",
    "        image=image[:4000,:,:,np.newaxis]\n",
    "        y=np.array(img_mask)\n",
    "        y=y[:4000,:,:,np.newaxis]\n",
    "\n",
    "        startidx = 0\n",
    "        endidx = 32\n",
    "        for i in range(len(image)//32):\n",
    "            image_list.append(centerVideo(image[startidx:endidx, ...].astype('float32')))\n",
    "            mask_list.append(y[startidx:endidx, ...].astype('float32'))\n",
    "            startidx += 32\n",
    "            endidx += 32\n",
    "\n",
    "    # Convert the lists into numpy arrays combining the first dimension\n",
    "    image = np.array(image_list)\n",
    "    y = np.array(mask_list)\n",
    "    \n",
    "    return image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different metrics for measuring the performance of the model\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the dice coefficient between the true and predicted masks\n",
    "\n",
    "    Parameters:\n",
    "    y_true (np.array): array of true masks\n",
    "    y_pred (np.array): array of predicted masks\n",
    "\n",
    "    Returns:\n",
    "    score (float): dice coefficient\n",
    "    \"\"\"\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = tf.cast(y_true_f, tf.float32)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the dice loss between the true and predicted masks\n",
    "\n",
    "    Parameters:\n",
    "    y_true (np.array): array of true masks\n",
    "    y_pred (np.array): array of predicted masks\n",
    "\n",
    "    Returns:\n",
    "    loss (float): dice loss\n",
    "    \"\"\"\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the binary cross entropy dice loss between the true and predicted masks\n",
    "\n",
    "    Parameters:\n",
    "    y_true (np.array): array of true masks\n",
    "    y_pred (np.array): array of predicted masks\n",
    "\n",
    "    Returns:\n",
    "    loss (float): binary cross entropy dice loss\n",
    "    \"\"\"\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all the different blocks and arrange them into the model\n",
    "# The end_block contains the LSTM layers and can be moved around in the model\n",
    "# Currently there is only LSTM on the first and last layers\n",
    "\n",
    "def conv_block(input, num_filters):\n",
    "    x = TimeDistributed(Conv2D(num_filters, 5, padding=\"same\"))(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = TimeDistributed(Conv2D(num_filters, 5, padding=\"same\"))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def deconv_block(input, num_filters):\n",
    "    x = TimeDistributed(Conv2D(num_filters, 5, padding=\"same\"))(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = TimeDistributed(Conv2D(num_filters, 5, padding=\"same\"))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def end_block(input, num_filters):\n",
    "    x = ConvLSTM2D(num_filters, 5, padding=\"same\", return_sequences=True)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = TimeDistributed(Conv2D(num_filters, 5, padding=\"same\"))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    return x, p\n",
    "\n",
    "def first_layer(input, num_filters):\n",
    "    x = end_block(input, num_filters)\n",
    "    p = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = TimeDistributed(Conv2DTranspose(num_filters, (2, 2), strides=(2,2), padding=\"same\"))(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = deconv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def last_layer(input, skip_features, num_filters):\n",
    "    x = TimeDistributed(Conv2DTranspose(num_filters, (2, 2), strides=(2,2), padding=\"same\"))(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = end_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def create_model(input_shape=(None, 128, 128, 1)):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    s1, p1 = first_layer(inputs, 40)\n",
    "    s2, p2 = encoder_block(p1, 64)\n",
    "    s3, p3 = encoder_block(p2, 128)\n",
    "\n",
    "    d1 = conv_block(p3, 256)\n",
    "\n",
    "    d2 = decoder_block(d1, s3, 128)\n",
    "    d3 = decoder_block(d2, s2, 64)\n",
    "    d4 = last_layer(d3, s1, 32)\n",
    "\n",
    "    classify = Conv3D(1, (1, 1, 1), padding=\"same\", activation='sigmoid')(d4)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main function that will train the model\n",
    "def main():\n",
    "    # Start by generating the pickle file (fill in path below if you already have a pickle file)\n",
    "    pickle_path = generate_pk(DATA_DIR)\n",
    "\n",
    "    # Read in the pickle file and prepare validation data\n",
    "    data, train_ids,val_ids = read_pk(pickle_path)\n",
    "    K.set_image_data_format('channels_last')\n",
    "    batch_size = 32\n",
    "    steps_per_epoch = (len(train_ids)*40)//batch_size\n",
    "    val, y_val = read_validation_files(data, val_ids)\n",
    "    print(f\"Length of training set: {len(train_ids)}, Length of validation set: {len(val_ids)}\")\n",
    "\n",
    "    # Optional: load in an existing model to fine tune rather than training from scratch\n",
    "    model = create_model()\n",
    "    # model = load_model(\"FlyNet.h5\", custom_objects = {'dice_coeff': dice_coeff, 'bce_dice_loss': bce_dice_loss, \"focal_tversky\": lf.Semantic_loss_functions().focal_tversky, \"log_cosh_dice_loss\": lf.Semantic_loss_functions().log_cosh_dice_loss})\n",
    "\n",
    "    # Set all remaining parameters and compile the model\n",
    "    lr = 1e-4\n",
    "    loss_function = lf.Semantic_loss_functions().log_cosh_dice_loss\n",
    "    model.compile(\n",
    "        loss=loss_function,\n",
    "        optimizer=Adam(lr),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.MeanIoU(num_classes=2),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            dice_coeff\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Optional: print out the model summary\n",
    "    # print(model.summary(line_length=150))\n",
    "\n",
    "    # Run the model\n",
    "    model_checkpoint = ModelCheckpoint(OUTPUT_DIR + \"/FlyNet_{epoch:02d}.h5\", monitor='val_loss', save_best_only=True)\n",
    "    # Optional: uncomment the line below to use tensorboard and add to list of callbacks in model.fit\n",
    "    # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=OUTPUT_DIR, histogram_freq=1)\n",
    "    model.fit(generateData(data, train_ids, batch_size), steps_per_epoch=steps_per_epoch, epochs=40, verbose=1, validation_data=(val, y_val), callbacks=[model_checkpoint])\n",
    "\n",
    "    return data, val_ids\n",
    "\n",
    "data, val_ids = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Drosophila_OCM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7d063505a178c6eab4f023e9fbe35e5295cec4d476ca87285bfce03130753f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
